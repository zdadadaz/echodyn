{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import echonet\n",
    "\n",
    "# matplotlib.use('agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadvideo(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError()\n",
    "    capture = cv2.VideoCapture(filename)\n",
    "\n",
    "    frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # empty numpy array of appropriate length, fill in when possible from front\n",
    "    v = np.zeros((frame_count, frame_width, frame_height, 3), np.float32)\n",
    "\n",
    "    for count in range(frame_count):\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            raise ValueError(\"Failed to load frame #{} of {}.\".format(count, filename))\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        v[count] = frame\n",
    "\n",
    "    v = v.transpose((3, 0, 1, 2))\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoid = \"0X22E82C3D081C819C\"\n",
    "path_base = '/home/jovyan/code/EchoNetDynamic/output/segmentation/deeplabv3_resnet50_random/labels'\n",
    "seg = np.load(os.path.join(path_base, videoid + \".npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 112, 112)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/home/jovyan/data/EchoNet-Dynamic/Videos/' + videoid + '.avi'\n",
    "video = loadvideo(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 172, 112, 112)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(video[:,0,...].transpose(1,2,0).astype(np.uint8))\n",
    "# plt.imshow(video)\n",
    "# plt.savefig('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 30.73it/s]\n"
     ]
    }
   ],
   "source": [
    "echonet.config.DATA_DIR = '../../data/EchoNet-Dynamic'\n",
    "mean, std = echonet.utils.get_mean_and_std(echonet.datasets.Echo(split=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(mean, int) or isinstance(mean, float):\n",
    "    video = (video - mean) / std\n",
    "else:\n",
    "    video = (video - mean.reshape(3, 1, 1, 1)) / std.reshape(3, 1, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = video[:,0,...].transpose(1,2,0).copy()\n",
    "tmp = (tmp - tmp.min())/(tmp.max()-tmp.min())\n",
    "cv2.imwrite('test_normalized.png', np.uint8(tmp*255)) \n",
    "video = video- video.mean()\n",
    "tmp = video\n",
    "video[tmp!=0] = -video[tmp!=0]\n",
    "video = (video - video.min())/(video.max()-video.min())\n",
    "# # plt.imshow(np.uint8(video[:,0,...].transpose(1,2,0)*255))\n",
    "# # plt.savefig('test_normalized.png')\n",
    "cv2.imwrite('test_normalized_inverse.png', np.uint8(video[:,0,...].transpose(1,2,0)*255)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 172, 112, 112)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 1.5 # Contrast control (1.0-3.0)\n",
    "beta = 0 # Brightness control (0-100)\n",
    "tmp = video[:,0,...].transpose(1,2,0).copy()\n",
    "adjusted = cv2.convertScaleAbs(tmp , alpha=alpha, beta=beta)\n",
    "adjusted = (adjusted - adjusted.min())/(adjusted.max()-adjusted.min())\n",
    "cv2.imwrite('adjusted_normalized.png', np.uint8(adjusted*255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n"
     ]
    }
   ],
   "source": [
    "print(adjusted.min(),adjusted.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 172, 112, 112)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(seg.max(),seg.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg[seg<0] = 0\n",
    "seg = seg/seg.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg = seg[..., np.newaxis]\n",
    "# plt.imshow(seg[0,...])\n",
    "# plt.savefig('seg.png')\n",
    "for i in range(10):\n",
    "    cv2.imwrite('seg_{}.png'.format(i), np.uint8(seg[i,...]*255)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_inverse(seg,video,name):\n",
    "    seg_mask = np.zeros((112,112,3))\n",
    "    video_out = np.zeros((112,112,3))\n",
    "    video_out_blur = np.zeros((112,112,3))\n",
    "    video_tmp = video.transpose(1,2,0)\n",
    "    for i in range(3):\n",
    "    #     seg_mask[...,i] = seg[0,...]\n",
    "        seg_tmp = cv2.GaussianBlur(np.uint8(seg*255),(31,31),5)\n",
    "        video_out[...,i] = seg*video_tmp[...,i]/seg.sum()\n",
    "        video_out_blur[...,i] = seg_tmp*video_tmp[...,i]/seg_tmp.sum()\n",
    "    video_out = (video_out - video_out.min())/ (video_out.max()-video_out.min())\n",
    "    video_out_blur = (video_out_blur - video_out_blur.min())/ (video_out_blur.max()-video_out_blur.min())\n",
    "    cv2.imwrite(name + '_test_normalized_inverse_seg.png', np.uint8(video_out*255)) \n",
    "    cv2.imwrite(name +'_test_normalized_inverse_seg_blur.png', np.uint8(video_out_blur*255)) \n",
    "\n",
    "seg_inverse(seg[0,...],video[:,0,...],'seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def _defaultdict_of_lists():\n",
    "    return collections.defaultdict(list)\n",
    "frames = collections.defaultdict(list)\n",
    "trace = collections.defaultdict(_defaultdict_of_lists)\n",
    "folder = '/home/jovyan/data/EchoNet-Dynamic/'\n",
    "with open(folder + \"VolumeTracings.csv\") as f:\n",
    "    header = f.readline().strip().split(\",\")\n",
    "    for (i, line) in enumerate(f):\n",
    "        filename, x1, y1, x2, y2, frame = line.strip().split(',')\n",
    "        x1 = float(x1)\n",
    "        y1 = float(y1)\n",
    "        x2 = float(x2)\n",
    "        y2 = float(y2)\n",
    "        frame = int(frame)\n",
    "        if frame not in trace[filename]:\n",
    "            frames[filename].append(frame)\n",
    "        trace[filename][frame].append((x1, y1, x2, y2))\n",
    "for filename in frames:\n",
    "    for frame in frames[filename]:\n",
    "        trace[filename][frame] = np.array(trace[filename][frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "large = trace[videoid][frames[videoid][-1]]\n",
    "small = trace[videoid][frames[videoid][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "def draw_mask(t):\n",
    "    x1, y1, x2, y2 = t[:, 0], t[:, 1], t[:, 2], t[:, 3]\n",
    "    x = np.concatenate((x1[1:], np.flip(x2[1:])))\n",
    "    y = np.concatenate((y1[1:], np.flip(y2[1:])))\n",
    "    r, c = skimage.draw.polygon(np.rint(y).astype(np.int), np.rint(x).astype(np.int), (video.shape[2], video.shape[3]))\n",
    "    mask = np.zeros((video.shape[2], video.shape[3]), np.float32)\n",
    "    mask[r, c] = 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "large = draw_mask(large)\n",
    "small = draw_mask(small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_inverse(large,video[:,31,...],'large')\n",
    "seg_inverse(small,video[:,2,...],'small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imwrite('large.png', np.uint8(large*255)) \n",
    "# cv2.imwrite('small.png', np.uint8(small*255)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = seg[:32,...]\n",
    "size = (logit > 0).sum(2).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1515, 1699, 1933, 1769, 1766, 1905, 1908, 1594, 1408, 1246, 1367,\n",
       "       1173, 1076, 1175, 1211, 1187, 1262, 1337, 1432, 1433, 1347, 1315,\n",
       "       1235, 1280, 1143, 1270, 1198, 1177, 1031, 1045, 1020,  994])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 2\n"
     ]
    }
   ],
   "source": [
    "print(size.argmin(),size.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_inverse(logit[31,...],video[:,31,...],'large_seg')\n",
    "seg_inverse(logit[2,...],video[:,2,...],'small_seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
